{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Space X  Falcon 9 First Stage Landing Prediction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping Falcon 9 and Falcon Heavy Launches Records from Wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **40** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be performing web scraping to collect Falcon 9 historical launch records from a Wikipedia page titled `List of Falcon 9 and Falcon Heavy launches`\n",
    "\n",
    "[https://en.wikipedia.org/wiki/List_of_Falcon\\_9\\_and_Falcon_Heavy_launches](https://en.wikipedia.org/wiki/List_of_Falcon\\_9\\_and_Falcon_Heavy_launches?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module\\_1\\_L2/images/Falcon9\\_rocket_family.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Falcon 9 first stage will land successfully\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/landing\\_1.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several examples of an unsuccessful landing are shown here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/api/Images/crash.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, the launch records are stored in a HTML table shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module\\_1\\_L2/images/falcon9-launches-wiki.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Web scrap Falcon 9 launch records with `BeautifulSoup`:\n",
    "\n",
    "*   Extract a Falcon 9 launch records HTML table from Wikipedia\n",
    "*   Parse the table and convert it into a Pandas data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import required packages for this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lutol\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lutol\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we will provide some helper functions for you to process web scraped HTML table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the data and time from the HTML  table cell\n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]\n",
    "\n",
    "def booster_version(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the booster version from the HTML  table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])\n",
    "    return out\n",
    "\n",
    "def landing_status(table_cells):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    out=[i for i in table_cells.strings][0]\n",
    "    return out\n",
    "\n",
    "\n",
    "def get_mass(table_cells):\n",
    "    mass=unicodedata.normalize(\"NFKD\", table_cells.text).strip()\n",
    "    if mass:\n",
    "        mass.find(\"kg\")\n",
    "        new_mass=mass[0:mass.find(\"kg\")+2]\n",
    "    else:\n",
    "        new_mass=0\n",
    "    return new_mass\n",
    "\n",
    "\n",
    "def extract_column_from_header(row):\n",
    "    \"\"\"\n",
    "    This function returns the landing status from the HTML table cell \n",
    "    Input: the  element of a table data cell extracts extra row\n",
    "    \"\"\"\n",
    "    if (row.br):\n",
    "        row.br.extract()\n",
    "    if row.a:\n",
    "        row.a.extract()\n",
    "    if row.sup:\n",
    "        row.sup.extract()\n",
    "        \n",
    "    colunm_name = ' '.join(row.contents)\n",
    "    \n",
    "    # Filter the digit and empty names\n",
    "    if not(colunm_name.strip().isdigit()):\n",
    "        colunm_name = colunm_name.strip()\n",
    "        return colunm_name    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the lab tasks consistent, you will be asked to scrape the data from a snapshot of the  `List of Falcon 9 and Falcon Heavy launches` Wikipage updated on\n",
    "`9th June 2021`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_url = \"https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, request the HTML page from the above URL and get a `response` object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1: Request the Falcon9 Launch Wiki page from its URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's perform an HTTP GET method to request the Falcon9 Launch HTML page, as an HTTP response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use requests.get() method with the provided static_url\n",
    "# assign the response to a object\n",
    "response = requests.get(static_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `BeautifulSoup` object from the HTML `response`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BeautifulSoup() to create a BeautifulSoup object from a response text content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the page title to verify if the `BeautifulSoup` object was created properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Falcon 9 and Falcon Heavy launches - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "# Use soup.title attribute\n",
    "title = soup.title.string\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2: Extract all column/variable names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to collect all relevant column names from the HTML table header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find all tables on the wiki page first. If you need to refresh your memory about `BeautifulSoup`, please check the external reference link towards the end of this lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date andtime (UTC)', 'Version,Booster [b]', 'Launch site', 'Payload[c]', 'Payload mass', 'Orbit', 'Customer', 'Launchoutcome', 'Boosterlanding']\n"
     ]
    }
   ],
   "source": [
    "# Use the find_all function in the BeautifulSoup object, with element type `table`\n",
    "# Assign the result to a list called `html_tables`\n",
    "# Find the table element by its class attribute\n",
    "table = soup.find('table', class_='wikitable')\n",
    "\n",
    "# Extract the table header\n",
    "thead = table.find('thead')\n",
    "\n",
    "# If thead is None, extract rows from the table element\n",
    "if thead is None:\n",
    "    rows = table.find_all('tr')\n",
    "    header_row = rows[0]\n",
    "else:\n",
    "    # Extract the table row(s) from the header\n",
    "    rows = thead.find_all('tr')\n",
    "    header_row = rows[0]\n",
    "# Extract the text content of each cell in the header row\n",
    "html_tables = [cell.text.strip() for cell in header_row.find_all('th')]\n",
    "\n",
    "# Print the table header cells\n",
    "print(html_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the third table is our target table contains the actual launch records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version,Booster [b]\n"
     ]
    }
   ],
   "source": [
    "# Let's print the third table and check its content\n",
    "first_launch_table = html_tables[2]\n",
    "print(first_launch_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should able to see the columns names embedded in the table header elements `<th>` as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "<tr>\n",
    "<th scope=\"col\">Flight No.\n",
    "</th>\n",
    "<th scope=\"col\">Date and<br/>time (<a href=\"/wiki/Coordinated_Universal_Time\" title=\"Coordinated Universal Time\">UTC</a>)\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/List_of_Falcon_9_first-stage_boosters\" title=\"List of Falcon 9 first-stage boosters\">Version,<br/>Booster</a> <sup class=\"reference\" id=\"cite_ref-booster_11-0\"><a href=\"#cite_note-booster-11\">[b]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Launch site\n",
    "</th>\n",
    "<th scope=\"col\">Payload<sup class=\"reference\" id=\"cite_ref-Dragon_12-0\"><a href=\"#cite_note-Dragon-12\">[c]</a></sup>\n",
    "</th>\n",
    "<th scope=\"col\">Payload mass\n",
    "</th>\n",
    "<th scope=\"col\">Orbit\n",
    "</th>\n",
    "<th scope=\"col\">Customer\n",
    "</th>\n",
    "<th scope=\"col\">Launch<br/>outcome\n",
    "</th>\n",
    "<th scope=\"col\"><a href=\"/wiki/Falcon_9_first-stage_landing_tests\" title=\"Falcon 9 first-stage landing tests\">Booster<br/>landing</a>\n",
    "</th></tr>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to iterate through the `<th>` elements and apply the provided `extract_column_from_header()` to extract column name one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "for th in header_row.find_all('th'):\n",
    "    name = extract_column_from_header(th)\n",
    "    if name is not None and len(name) > 0:\n",
    "        column_names.append(name)\n",
    "\n",
    "# Apply find_all() function with `th` element on first_launch_table\n",
    "# Iterate each th element and apply the provided extract_column_from_header() to get a column name\n",
    "# Append the Non-empty column name (`if name is not None and len(name) > 0`) into a list called column_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the extracted column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flight No.', 'Date and time ( )', 'Launch site', 'Payload', 'Payload mass', 'Orbit', 'Customer', 'Launch outcome']\n"
     ]
    }
   ],
   "source": [
    "print(column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3: Create a data frame by parsing the launch HTML tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an empty dictionary with keys from the extracted column names in the previous task. Later, this dictionary will be converted into a Pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_dict= dict.fromkeys(column_names)\n",
    "\n",
    "# Remove an irrelvant column\n",
    "del launch_dict['Date and time ( )']\n",
    "\n",
    "# Let's initial the launch_dict with each value to be an empty list\n",
    "launch_dict['Flight No.'] = []\n",
    "launch_dict['Launch Site'] = []\n",
    "launch_dict['Payload'] = []\n",
    "launch_dict['Payload mass'] = []\n",
    "launch_dict['Orbit'] = []\n",
    "launch_dict['Customer'] = []\n",
    "launch_dict['Launch outcome'] = []\n",
    "# Added some new columns\n",
    "launch_dict['Version Booster']=[]\n",
    "launch_dict['Booster landing']=[]\n",
    "launch_dict['Date']=[]\n",
    "launch_dict['Time']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to fill up the `launch_dict` with launch records extracted from table rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, HTML tables in Wiki pages are likely to contain unexpected annotations and other types of noises, such as reference links `B0004.1[8]`, missing values `N/A [e]`, inconsistent formatting, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the parsing process, we have provided an incomplete code snippet below to help you to fill up the `launch_dict`. Please complete the following code snippet with TODOs or you can choose to write your own logic to parse all launch tables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_row = 0\n",
    "#Extract each table \n",
    "for table_number,table in enumerate(soup.find_all('table',\"wikitable plainrowheaders collapsible\")):\n",
    "   # get table row \n",
    "    for rows in table.find_all(\"tr\"):\n",
    "        #check to see if first table heading is as number corresponding to launch a number \n",
    "        if rows.th:\n",
    "            if rows.th.string:\n",
    "                flight_number=rows.th.string.strip()\n",
    "                flag=flight_number.isdigit()\n",
    "        else:\n",
    "            flag=False\n",
    "        #get table element \n",
    "        row=rows.find_all('td')\n",
    "        #if it is number save cells in a dictonary \n",
    "        if flag:\n",
    "            extracted_row += 1\n",
    "            # Flight Number value\n",
    "            # TODO: Append the flight_number into launch_dict with key `Flight No.`\n",
    "            launch_dict['Flight No.'].append(flight_number)\n",
    "            print(flight_number)\n",
    "            \n",
    "            datatimelist=date_time(row[0])\n",
    "            \n",
    "            # Date value\n",
    "            # TODO: Append the date into launch_dict with key `Date`\n",
    "            date = datatimelist[0].strip(',')\n",
    "            launch_dict['Date'].append(date)\n",
    "            print(date)\n",
    "            \n",
    "            # Time value\n",
    "            # TODO: Append the time into launch_dict with key `Time`\n",
    "            time = datatimelist[1]\n",
    "            launch_dict['Time'].append(time)\n",
    "            print(time)\n",
    "              \n",
    "            # Booster version\n",
    "            # TODO: Append the bv into launch_dict with key `Version Booster`\n",
    "            bv=booster_version(row[1])\n",
    "            if not(bv):\n",
    "                bv=row[1].a.string\n",
    "            launch_dict['Version Booster'].append(bv)\n",
    "            print(bv)\n",
    "            \n",
    "            # Launch Site\n",
    "            # TODO: Append the bv into launch_dict with key `Launch Site`\n",
    "            launch_site = row[2].a.string\n",
    "            launch_dict['Launch Site'].append(launch_site)\n",
    "            print(launch_site)\n",
    "            \n",
    "            # Payload\n",
    "            # TODO: Append the payload into launch_dict with key `Payload`\n",
    "            payload = row[3].a.string\n",
    "            launch_dict['Payload'].append(payload)\n",
    "            print(payload)\n",
    "            \n",
    "            # Payload Mass\n",
    "            # TODO: Append the payload_mass into launch_dict with key `Payload mass`\n",
    "            payload_mass = get_mass(row[4])\n",
    "            launch_dict['Payload mass'].append(payload_mass)\n",
    "            print(payload_mass)\n",
    "            \n",
    "            # Orbit\n",
    "            # TODO: Append the orbit into launch_dict with key `Orbit`\n",
    "            orbit = row[5].a.string\n",
    "            launch_dict['Orbit'].append(orbit)\n",
    "            print(orbit)\n",
    "            \n",
    "            # Customer\n",
    "            # TODO: Append the customer into launch_dict with key `Customer`\n",
    "            customer = row[6].a.string\n",
    "            launch_dict['Customer'].append(customer)\n",
    "            print(customer)\n",
    "            \n",
    "            # Launch outcome\n",
    "            # TODO: Append the launch_outcome into launch_dict with key `Launch outcome`\n",
    "            launch_outcome = list(row[7].strings)[0]\n",
    "            launch_dict['Launch outcome'].append(launch_outcome)\n",
    "            print(launch_outcome)\n",
    "            \n",
    "            # Booster landing\n",
    "            # TODO: Append the launch_outcome into launch_dict with key `Booster landing`\n",
    "            booster_landing = landing_status(row[8])\n",
    "            launch_dict['Booster landing'].append(booster_landing)\n",
    "            print(booster_landing)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCSFS\n"
     ]
    }
   ],
   "source": [
    "print(launch_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight No.: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106']\n",
      "Launch site: None\n",
      "Payload: ['Dragon Spacecraft Qualification Unit', 'Dragon', 'Dragon', 'SpaceX CRS-1', 'SpaceX CRS-2', 'CASSIOPE', 'SES-8', 'Thaicom 6', 'SpaceX CRS-3', 'Orbcomm-OG2', 'AsiaSat 8', 'AsiaSat 6', 'SpaceX CRS-4', 'SpaceX CRS-5', 'DSCOVR', 'ABS-3A', 'SpaceX CRS-6', 'TürkmenÄlem 52°E / MonacoSAT', 'SpaceX CRS-7', 'Orbcomm-OG2', 'Jason-3', 'SES-9', 'SpaceX CRS-8', 'JCSAT-14', 'Thaicom 8', 'ABS-2A', 'SpaceX CRS-9', 'JCSAT-16', 'Iridium NEXT', 'SpaceX CRS-10', 'EchoStar 23', 'SES-10', 'NROL-76', 'Inmarsat-5 F4', 'SpaceX CRS-11', 'BulgariaSat-1', 'Iridium NEXT', 'Intelsat 35e', 'SpaceX CRS-12', 'Formosat-5', 'Boeing X-37B', 'Iridium NEXT', 'SES-11', 'Koreasat 5A', 'SpaceX CRS-13', 'Iridium NEXT', 'Zuma', 'GovSat-1', 'Paz', 'Hispasat 30W-6', 'Iridium NEXT', 'SpaceX CRS-14', 'Transiting Exoplanet Survey Satellite', 'Bangabandhu-1', 'Iridium NEXT', 'SES-12', 'SpaceX CRS-15', 'Telstar 19V', 'Iridium NEXT', 'Merah Putih', 'Telstar 18V', 'SAOCOM 1A', \"Es'hail 2\", 'SSO-A', 'SpaceX CRS-16', 'GPS III', 'Iridium NEXT', 'Nusantara Satu', 'Crew Dragon Demo-1', 'SpaceX CRS-17', 'Starlink', 'RADARSAT Constellation', 'SpaceX CRS-18', 'AMOS-17', 'Starlink', 'SpaceX CRS-19', 'JCSat-18', 'Starlink', 'Crew Dragon in-flight abort test', 'Starlink', 'Starlink', 'SpaceX CRS-20', 'Starlink', 'Starlink', 'Crew Dragon Demo-2', 'Starlink', 'Starlink', 'GPS III', 'ANASIS-II', 'Starlink', 'Starlink', 'SAOCOM 1B', 'Starlink', 'Starlink', 'Starlink', 'Starlink', 'GPS III', 'Crew-1', 'Sentinel-6 Michael Freilich (Jason-CS A)', 'Starlink', 'SpaceX CRS-21', 'SXM-7', 'NROL-108', 'Türksat 5A', 'Starlink', 'Transporter-1']\n",
      "Payload mass: [0, 0, '525 kg', '4,700 kg', '4,877 kg', '500 kg', '3,170 kg', '3,325 kg', '2,296 kg', '1,316 kg', '4,535 kg', '4,428 kg', '2,216 kg', '2,395 kg', '570 kg', '4,159 kg', '1,898 kg', '4,707 kg', '1,952 kg', '2,034 kg', '553 kg', '5,271 kg', '3,136 kg', '4,696 kg', '3,100 kg', '3,600 kg', '2,257 kg', '4,600 kg', '9,600 kg', '2,490 kg', '5,600 kg', '5,300 kg', 'C', '6,070 kg', '2,708 kg', '3,669 kg', '9,600 kg', '6,761 kg', '3,310 kg', '475 kg', '4,990 kg', '9,600 kg', '5,200 kg', '3,500 kg', '2,205 kg', '9,600 kg', 'C', '4,230 kg', '2,150 kg', '6,092 kg', '9,600 kg', '2,647 kg', '362 kg', '3,600 kg', '6,460 kg', '5,384 kg', '2,697 kg', '7,075 kg', '9,600 kg', '5,800 kg', '7,060 kg', '3,000 kg', '5,300 kg', '~4,000 kg', '2,500 kg', '4,400 kg', '9,600 kg', '4,850 kg', '12,055 kg', '2,495 kg', '13,620 kg', '4,200 kg', '2,268 kg', '6,500 kg', '15,600 kg', '2,617 kg', '6,956 kg', '15,600 kg', '12,050 kg', '15,600 kg', '15,600 kg', '1,977 kg', '15,600 kg', '15,600 kg', '12,530 kg', '15,600 kg', '15,410 kg', '4,311 kg', '5,000–6,000 kg', '14,932 kg', '~15,440 kg', '3,130 kg', '15,600 kg', '15,600 kg', '15,600 kg', '15,600 kg', '4,311 kg', '~12,500 kg', '1,192 kg', '15,600 kg', '2,972 kg', '7,000 kg', 'C', '3,500 kg', '15,600 kg', '~5,000 kg']\n",
      "Orbit: ['LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'Polar orbit', 'GTO', 'GTO', 'LEO', 'LEO', 'GTO', 'GTO', 'LEO', 'LEO', 'HEO', 'GTO', 'LEO', 'GTO', 'LEO', 'LEO', 'LEO', 'GTO', 'LEO', 'GTO', 'GTO', 'GTO', 'LEO', 'GTO', 'Polar', 'LEO', 'GTO', 'GTO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'SSO', 'LEO', 'Polar', 'GTO', 'GTO', 'LEO', 'Polar', 'LEO', 'GTO', 'SSO', 'GTO', 'Polar', 'LEO', 'HEO', 'GTO', 'Polar', 'GTO', 'LEO', 'GTO', 'Polar', 'GTO', 'GTO', 'SSO', 'GTO', 'SSO', 'LEO', 'MEO', 'Polar', 'GTO', 'LEO', 'LEO', 'LEO', 'SSO', 'LEO', 'GTO', 'LEO', 'LEO', 'GTO', 'LEO', 'Sub-orbital', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'LEO', 'MEO', 'GTO', 'LEO', 'LEO', 'SSO', 'LEO', 'LEO', 'LEO', 'LEO', 'MEO', 'LEO', 'LEO', 'LEO', 'LEO', 'GTO', 'LEO', 'GTO', 'LEO', 'SSO']\n",
      "Customer: ['SpaceX', 'NASA', 'NASA', 'NASA', 'NASA', 'MDA', 'SES', 'Thaicom', 'NASA', 'Orbcomm', 'AsiaSat', 'AsiaSat', 'NASA', 'NASA', 'USAF', 'ABS', 'NASA', None, 'NASA', 'Orbcomm', 'NASA', 'SES', 'NASA', 'SKY Perfect JSAT Group', 'Thaicom', 'ABS', 'NASA', 'SKY Perfect JSAT Group', 'Iridium Communications', 'NASA', 'EchoStar', 'SES', 'NRO', 'Inmarsat', 'NASA', 'Bulsatcom', 'Iridium Communications', 'Intelsat', 'NASA', 'NSPO', 'USAF', 'Iridium Communications', 'SES S.A.', 'KT Corporation', 'NASA', 'Iridium Communications', 'Northrop Grumman', 'SES', 'Hisdesat', 'Hispasat', 'Iridium Communications', 'NASA', 'NASA', 'Thales-Alenia', 'Iridium Communications', 'SES', 'NASA', 'Telesat', 'Iridium Communications', 'Telkom Indonesia', 'Telesat', 'CONAE', \"Es'hailSat\", 'Spaceflight Industries', 'NASA', 'USAF', 'Iridium Communications', 'PSN', 'NASA', 'NASA', 'SpaceX', 'Canadian Space Agency', 'NASA', 'Spacecom', 'SpaceX', 'NASA', 'Sky Perfect JSAT', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'NASA', 'SpaceX', 'SpaceX', 'U.S. Space Force', 'Republic of Korea Army', 'SpaceX', 'SpaceX', 'CONAE', 'SpaceX', 'SpaceX', 'SpaceX', 'SpaceX', 'USSF', 'NASA', 'NASA', 'SpaceX', 'NASA', 'Sirius XM', 'NRO', 'Türksat', 'SpaceX']\n",
      "Launch outcome: ['Success\\n', 'Success', 'Success', 'Success\\n', 'Success\\n', 'Success', 'Success', 'Success', 'Success\\n', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Failure', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success\\n', 'Success', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n', 'Success\\n']\n",
      "Launch Site: ['CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'VAFB', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'Cape Canaveral', 'VAFB', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'KSC', 'VAFB', 'KSC', 'KSC', 'VAFB', 'KSC', 'VAFB', 'KSC', 'KSC', 'Cape Canaveral', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'KSC', 'VAFB', 'CCAFS', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'KSC', 'VAFB', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'VAFB', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'KSC', 'KSC', 'CCAFS', 'CCAFS', 'CCAFS', 'CCAFS', 'KSC', 'CCAFS', 'CCAFS', 'KSC', 'KSC', 'KSC', 'CCAFS', 'CCAFS', 'KSC', 'VAFB', 'CCAFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS', 'KSC', 'CCSFS']\n",
      "Version Booster: ['F9 v1.0B0003.1', 'F9 v1.0B0004.1', 'F9 v1.0B0005.1', 'F9 v1.0B0006.1', 'F9 v1.0B0007.1', 'F9 v1.1B1003', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 v1.1', 'F9 FT', 'F9 v1.1', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FT♺', 'F9 FT', 'F9 FT', 'F9 FT', 'F9 FTB1029.2', 'F9 FT', 'F9 FT', 'F9 B4', 'F9 FT', 'F9 B4', 'F9 B4', 'F9 FTB1031.2', 'F9 B4', 'F9 FTB1035.2', 'F9 FTB1036.2', 'F9 B4', 'F9 FTB1032.2', 'F9 FTB1038.2', 'F9 B4', 'F9 B4B1041.2', 'F9 B4B1039.2', 'F9 B4', 'F9 B5B1046.1', 'F9 B4B1043.2', 'F9 B4B1040.2', 'F9 B4B1045.2', 'F9 B5', 'F9 B5B1048', 'F9 B5B1046.2', 'F9 B5', 'F9 B5B1048.2', 'F9 B5B1047.2', 'F9 B5B1046.3', 'F9 B5', 'F9 B5', 'F9 B5B1049.2', 'F9 B5B1048.3', 'F9 B5[268]', 'F9 B5', 'F9 B5B1049.3', 'F9 B5B1051.2', 'F9 B5B1056.2', 'F9 B5B1047.3', 'F9 B5', 'F9 B5', 'F9 B5B1056.3', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5B1058.2', 'F9 B5', 'F9 B5B1049.6', 'F9 B5', 'F9 B5B1060.2', 'F9 B5B1058.3', 'F9 B5B1051.6', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5', 'F9 B5 ♺', 'F9 B5 ♺', 'F9 B5 ♺', 'F9 B5 ♺', 'F9 B5', 'F9 B5B1051.8', 'F9 B5B1058.5']\n",
      "Booster landing: ['Failure', 'Failure', 'No attempt\\n', 'No attempt', 'No attempt\\n', 'Uncontrolled', 'No attempt', 'No attempt', 'Controlled', 'Controlled', 'No attempt', 'No attempt\\n', 'Uncontrolled', 'Failure ', 'Controlled', 'No attempt', 'Failure', 'No attempt', 'Precluded', 'Success', 'Failure', 'Failure', 'Success', 'Success', 'Success', 'Failure', 'Success', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Controlled', 'Success', 'Controlled', 'No attempt', 'No attempt', 'No attempt', 'No attempt', 'Success', 'Success', 'No attempt', 'No attempt', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Failure', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'No attempt', 'Success', 'Success', 'Success', 'Success', 'No attempt\\n', 'Success', 'Failure', 'Success', 'Failure', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success', 'Success']\n",
      "Date: ['4 June 2010', '8 December 2010', '22 May 2012', '8 October 2012', '1 March 2013', '29 September 2013', '3 December 2013', '6 January 2014', '18 April 2014', '14 July 2014', '5 August 2014', '7 September 2014', '21 September 2014', '10 January 2015', '11 February 2015', '2 March 2015', '14 April 2015', '27 April 2015', '28 June 2015', '22 December 2015', '17 January 2016', '4 March 2016', '8 April 2016', '6 May 2016', '27 May 2016', '15 June 2016', '18 July 2016', '14 August 2016', '14 January 2017', '19 February 2017', '16 March 2017', '30 March 2017', '1 May 2017', '15 May 2017', '3 June 2017', '23 June 2017', '25 June 2017', '5 July 2017', '14 August 2017', '24 August 2017', '7 September 2017', '9 October 2017', '11 October 2017', '30 October 2017', '15 December 2017', '23 December 2017', '8 January 2018', '31 January 2018', '22 February 2018', '6 March 2018', '30 March 2018', '2 April 2018', '18 April 2018', '11 May 2018', '22 May 2018', '4 June 2018', '29 June 2018', '22 July 2018', '25 July 2018', '7 August 2018', '10 September 2018', '8 October 2018', '15 November 2018', '3 December 2018', '5 December 2018', '23 December 2018', '11 January 2019', '22 February 2019', '2 March 2019', '4 May 2019', '24 May 2019', '12 June 2019', '25 July 2019', '6 August 2019', '11 November 2019', '5 December 2019', '17 December 2019', '7 January 2020', '19 January 2020', '29 January 2020', '17 February 2020', '7 March 2020', '18 March 2020', '22 April 2020', '30 May 2020', '4 June 2020', '13 June 2020', '30 June 2020', '20 July 2020', '7 August 2020', '18 August 2020', '30 August 2020', '3 September 2020', '6 October 2020', '18 October 2020', '24 October 2020', '5 November 2020', '16 November 2020', '21 November 2020', '25 November 2020', '6 December 2020', '13 December 2020', '19 December 2020', '8 January 2021', '20 January 2021', '24 January 2021']\n",
      "Time: ['18:45', '15:43', '07:44', '00:35', '15:10', '16:00', '22:41', '22:06', '19:25', '15:15', '08:00', '05:00', '05:52', '09:47', '23:03', '03:50', '20:10', '23:03', '14:21', '01:29', '18:42', '23:35', '20:43', '05:21', '21:39', '14:29', '04:45', '05:26', '17:54', '14:39', '06:00', '22:27', '11:15', '23:21', '21:07', '19:10', '20:25', '23:38', '16:31', '18:51', '14:00', '12:37', '22:53:00', '19:34', '15:36', '01:27', '01:00', '21:25', '14:17', '05:33', '14:14', '20:30', '22:51', '20:14', '19:47', '04:45', '09:42', '05:50', '11:39', '05:18', '04:45', '02:22', '20:46', '18:34:05', '18:16', '13:51', '15:31', '01:45', '07:49', '06:48', '02:30', '14:17', '22:01', '23:23', '14:56', '17:29', '00:10', '02:19:21', '15:30', '14:07', '15:05', '04:50', '12:16', '19:30', '19:22', '01:25', '09:21', '20:10:46', '21:30', '05:12', '14:31', '23:18', '12:46:14', '11:29:34', '12:25:57', '15:31:34', '23:24:23', '00:27', '17:17:08', '02:13', '16:17:08', '17:30:00', '14:00:00', '02:15', '13:02', '15:00']\n"
     ]
    }
   ],
   "source": [
    "for col, values in launch_dict.items():\n",
    "    print(f\"{col}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have fill in the parsed launch record values into `launch_dict`, you can create a dataframe from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in launch_dict.keys():\n",
    "    unique_values = set(launch_dict[col])\n",
    "    print(f\"Unique values in {col}: {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df=pd.DataFrame(launch_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export it to a <b>CSV</b> for the next section, but to make the answers consistent and in case you have difficulties finishing this lab.\n",
    "\n",
    "Following labs will be using a provided dataset to make each lab independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>df.to_csv('spacex_web_scraped.csv', index=False)</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">Yan Luo</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.linkedin.com/in/nayefaboutayoun/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">Nayef Abou Tayoun</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description          |\n",
    "| ----------------- | ------- | ---------- | --------------------------- |\n",
    "| 2021-06-09        | 1.0     | Yan Luo    | Tasks updates               |\n",
    "| 2020-11-10        | 1.0     | Nayef      | Created the initial version |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2021 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
